{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EDPFJNk-7bD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/SkinCancerData\"\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "id": "q9AtHcAVVfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision timm albumentations opencv-python matplotlib"
      ],
      "metadata": {
        "id": "nkQe_w_GVl70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/SkinCancerData\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "hWBxmfQMVvqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create train-test split**"
      ],
      "metadata": {
        "id": "QmNHDL8FV9W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=16)\n",
        "test_loader = DataLoader(test_ds, batch_size=16)"
      ],
      "metadata": {
        "id": "EtgPOGk4V7x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "model.classifier[1] = nn.Linear(1280, 3)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EIGv4CdGWXcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(\"Epoch\", epoch+1, \"| Train Accuracy:\", correct / total)"
      ],
      "metadata": {
        "id": "2JZdSEzaWbXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/skin_model.pth\")"
      ],
      "metadata": {
        "id": "GWsk7q7yWjEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb"
      ],
      "metadata": {
        "id": "tpTuZXTk4GyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "st.set_page_config(layout=\"centered\")\n",
        "st.title(\"Skin Cancer Detector with GradCAM\")\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "# Load model\n",
        "model = efficientnet_b0(weights=None)\n",
        "model.classifier[1] = nn.Linear(1280, 3)\n",
        "model.load_state_dict(torch.load(\"skin_model.pth\", map_location=device))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "labels = [\"AK\", \"BCC\", \"SK\"]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# GradCAM helper\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer=None):\n",
        "        self.model = model\n",
        "        if target_layer is None:\n",
        "            target_layer = None\n",
        "            for name, module in reversed(list(model.named_modules())):\n",
        "                if isinstance(module, nn.Conv2d):\n",
        "                    target_layer = module\n",
        "                    break\n",
        "            if target_layer is None:\n",
        "                raise ValueError(\"No Conv2d layer found in model\")\n",
        "        self.target_layer = target_layer\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        def forward_hook(module, inp, out):\n",
        "            self.activations = out.detach()\n",
        "\n",
        "        def backward_hook(module, grad_in, grad_out):\n",
        "            self.gradients = grad_out[0].detach()\n",
        "\n",
        "        self.target_layer.register_forward_hook(forward_hook)\n",
        "        self.target_layer.register_full_backward_hook(backward_hook)\n",
        "\n",
        "    def __call__(self, input_tensor, class_idx=None):\n",
        "        input_tensor = input_tensor.clone().to(next(self.model.parameters()).device)\n",
        "        input_tensor.requires_grad_(True)\n",
        "\n",
        "        outputs = self.model(input_tensor)\n",
        "        if class_idx is None:\n",
        "            class_idx = int(outputs.argmax(dim=1).item())\n",
        "\n",
        "        score = outputs[0, class_idx]\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=False)\n",
        "\n",
        "        grads = self.gradients[0]\n",
        "        acts = self.activations[0]\n",
        "\n",
        "        weights = grads.mean(dim=(1,2))\n",
        "\n",
        "        cam = torch.zeros(acts.shape[1:], dtype=acts.dtype, device=acts.device)\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * acts[i]\n",
        "\n",
        "        cam = torch.relu(cam)\n",
        "        cam = cam - cam.min()\n",
        "        if cam.max() != 0:\n",
        "            cam = cam / cam.max()\n",
        "\n",
        "        cam_np = cam.detach().cpu().numpy()\n",
        "        probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()[0]\n",
        "        conf = float(probs[class_idx])\n",
        "\n",
        "        return cam_np, class_idx, conf\n",
        "\n",
        "def apply_heatmap_on_image(img_pil, cam_np, alpha=0.5):\n",
        "    W_img, H_img = img_pil.size\n",
        "    cam_resized = cv2.resize((cam_np * 255).astype(np.uint8), (W_img, H_img))\n",
        "    heatmap = cv2.applyColorMap(cam_resized, cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img = np.array(img_pil.convert(\"RGB\"))\n",
        "    overlay = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    return Image.fromarray(overlay)\n",
        "\n",
        "uploaded = st.file_uploader(\"Upload skin image\", type=[\"jpg\",\"jpeg\",\"png\"])\n",
        "\n",
        "if uploaded:\n",
        "    img = Image.open(uploaded).convert(\"RGB\")\n",
        "\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(img_tensor)\n",
        "        prob = torch.softmax(out, dim=1)[0].detach().cpu().numpy()\n",
        "        pred_idx = int(prob.argmax())\n",
        "        conf = float(prob[pred_idx])\n",
        "\n",
        "    gradcam = GradCAM(model)\n",
        "    cam_np, class_idx, conf2 = gradcam(img_tensor)\n",
        "    heatmap_img = apply_heatmap_on_image(img, cam_np)\n",
        "\n",
        "    # ---------- NEW UI LAYOUT ----------\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.image(img, caption=\"Preview\", width=320)\n",
        "\n",
        "    with col2:\n",
        "        st.image(heatmap_img, caption=\"Model Attention Heatmap\", width=320)\n",
        "\n",
        "    st.markdown(\n",
        "        f\"<h3 style='text-align:center;'>Prediction: {labels[pred_idx]} â€” {conf*100:.1f} percent</h3>\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "    # ---------- END UI LAYOUT ----------\n"
      ],
      "metadata": {
        "id": "UKpvGnEAwC7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &>/dev/null &"
      ],
      "metadata": {
        "id": "H_z9KxD05FQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ],
      "metadata": {
        "id": "kMax29jO9wcl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}